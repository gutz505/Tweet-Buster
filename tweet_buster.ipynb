{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Models we found\n",
    "In the following code cells you will find a selection of misinformation classifier models that are published on hugginface.co and directly applicable in our setup. To inspect a models details (training set, performance metrics, ets...) please follow the provided link to the respective model card. To load a model into the Tweet-Buster application simply execute the corresponding code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: https://huggingface.co/XSY/albert-base-v2-fakenews-discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('XSY/albert-base-v2-fakenews-discriminator')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('XSY/albert-base-v2-fakenews-discriminator')\n",
    "\n",
    "def get_veracity(text):\n",
    "    while True:\n",
    "        try:\n",
    "            tokens = tokenizer.encode(str(text), return_tensors='pt')\n",
    "            result = model(tokens)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if len(text) > 20:\n",
    "                text = text[:-10]\n",
    "            else:\n",
    "                return -1\n",
    "    return result.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: https://huggingface.co/hamzab/roberta-fake-news-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('hamzab/roberta-fake-news-classification')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('hamzab/roberta-fake-news-classification')\n",
    "\n",
    "def get_veracity(text):\n",
    "    while True:\n",
    "        try:\n",
    "            tokens = tokenizer.encode(str(text), return_tensors='pt')\n",
    "            result = model(tokens)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if len(text) > 20:\n",
    "                text = text[:-10]\n",
    "            else:\n",
    "                return -1\n",
    "    return result.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: https://huggingface.co/roupenminassian/TwHIN-BERT-Misinformation-Classifier   (2.25 GB!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roupenminassian/TwHIN-BERT-Misinformation-Classifier')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('roupenminassian/TwHIN-BERT-Misinformation-Classifier')\n",
    "\n",
    "def get_veracity(text):\n",
    "    while True:\n",
    "        try:\n",
    "            tokens = tokenizer.encode(str(text), return_tensors='pt')\n",
    "            result = model(tokens)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if len(text) > 20:\n",
    "                text = text[:-10]\n",
    "            else:\n",
    "                return -1\n",
    "    return result.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: https://huggingface.co/dlentr/lie_detection_distilbert/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('dlentr/lie_detection_distilbert')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('dlentr/lie_detection_distilbert')\n",
    "\n",
    "def get_veracity(text):\n",
    "    while True:\n",
    "        try:\n",
    "            tokens = tokenizer.encode(str(text), return_tensors='pt')\n",
    "            result = model(tokens)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if len(text) > 20:\n",
    "                text = text[:-10]\n",
    "            else:\n",
    "                return -1\n",
    "    return result.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: https://huggingface.co/mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis (3 Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis')\n",
    "\n",
    "def get_veracity(text):\n",
    "    while True:\n",
    "        try:\n",
    "            tokens = tokenizer.encode(str(text), return_tensors='pt')\n",
    "            result = model(tokens)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if len(text) > 20:\n",
    "                text = text[:-10]\n",
    "            else:\n",
    "                return -1\n",
    "    return result.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: https://huggingface.co/vectara/hallucination_evaluation_model (Probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('vectara/hallucination_evaluation_model')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('vectara/hallucination_evaluation_model')\n",
    "\n",
    "def get_veracity(text):\n",
    "    while True:\n",
    "        try:\n",
    "            tokens = tokenizer.encode(str(text), return_tensors='pt')\n",
    "            result = model(tokens)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if len(text) > 20:\n",
    "                text = text[:-10]\n",
    "            else:\n",
    "                return -1\n",
    "    tensor = result.logits\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: https://huggingface.co/HuggingFaceFW/fineweb-edu-classifier (Probability / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('HuggingFaceFW/fineweb-edu-classifier')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('HuggingFaceFW/fineweb-edu-classifier')\n",
    "\n",
    "def get_veracity(text):\n",
    "    while True:\n",
    "        try:\n",
    "            tokens = tokenizer.encode(str(text), return_tensors='pt')\n",
    "            result = model(tokens)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if len(text) > 20:\n",
    "                text = text[:-10]\n",
    "            else:\n",
    "                return -1\n",
    "    tensor = result.logits\n",
    "    value = tensor.item()\n",
    "    value = int(round(max(0, min(value, 5))))\n",
    "    value = value/5\n",
    "    tensor = tensor.detach()\n",
    "    tensor[0, 0] = value\n",
    "    tensor.requires_grad_(True)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: RANDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_veracity(text):\n",
    "    return torch.rand(1, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: ADD YOUR OWN\n",
    "\n",
    "Your resulting tensor should be of the following format: \n",
    "\n",
    "For probability classification:\n",
    "<code>tensor([[0.5]], requires_grad=True)</code>\n",
    "\n",
    "For class classification:\n",
    "<code>tensor([[0.01,  0.99]], requires_grad=True)</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_veracity(text):\n",
    "    \n",
    "    # Your model code here\n",
    "\n",
    "    tensor = torch.rand(1, 1, requires_grad=True) #<-- Store your result in to the tensor variable\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Model\n",
    "The following code cell gives you the opportunity to test the loaded model before deploying it in on live streamed Twitter (X) data. The text from the test sample is sourced from a tweet made by Donald J. Trump, however you can change it to you liking. If the model works as intended you should receive the number of possible classes and the outcome of the model in the cell output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible Classes: 1\n",
      "Outcome: 0.23633378744125366\n"
     ]
    }
   ],
   "source": [
    "text = 'The 75,000,000 great American Patriots who voted for me, AMERICA FIRST, and MAKE AMERICA GREAT AGAIN, will have a GIANT VOICE long into the future. They will not be disrespected or treated unfairly in any way, shape or form!!!'\n",
    "classification = get_veracity(text)\n",
    "if len(classification.tolist()[0]) > 1:\n",
    "    print('Number of possible Classes: ' + str(len(classification.tolist()[0])))\n",
    "    print('Outcome: ' + str(int(torch.argmax(classification))))\n",
    "else:\n",
    "    print('Number of possible Classes: 1')\n",
    "    print('Outcome: ' + str(classification.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Text Sanitization and Response Classes\n",
    "The following code imports the Flask libraries, sets up a function for tweet-text sanitization and initializes a list storing the response classes. A more transparent example of how our tweet-text sanitization is performed is given at the end of this notebook. You have the option to reverse the response classes and to display the classification output in your browser as emojis only. For this set the respective variable in the following code cell to 1 (reverse_resp_classes, emojis_only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Set your display preferences here!\n",
    "reverse_resp_classes = 0\n",
    "emojis_only = 0\n",
    "\n",
    "\n",
    "def get_tweet_text(select_tweet):\n",
    "    if re.match(r'^[^@]+@[^@]+·', select_tweet):\n",
    "        text = re.sub(r'^[^@]+@[^@]+·', '', select_tweet)\n",
    "        text = re.sub(r'^(?:[A-Za-z]{3}\\s\\d+|\\d+[hm])', '', text)\n",
    "        text = re.sub(r', \\d{4}', '', text)\n",
    "        if text .startswith('From'):\n",
    "            return 'SHORT'\n",
    "        text = re.sub(r'\\dFrom.*', '', text)\n",
    "        text = text.replace('views', '')\n",
    "        last_word = text.split()\n",
    "        last_word = last_word[-1]\n",
    "        if bool(re.search(r'\\d', last_word)):\n",
    "            text = text.replace(last_word, '')\n",
    "            last_word = last_word[:re.search(r'\\d', last_word).start()]\n",
    "            text = text + last_word\n",
    "        if not bool(re.search(r'[a-zA-Z]{5,}', text)):\n",
    "            text = ''\n",
    "        return text\n",
    "    else:\n",
    "        return'THIS_TWEET_IS_AN_AD'\n",
    "\n",
    "\n",
    "response_classes = [['This is an AD! &#128566;'],\n",
    "                        ['Bli Bla Blup!'],\n",
    "                        ['Likely FALSE! &#128533;', 'Likely TRUE! &#128512;'],\n",
    "                        ['Likely FALSE! &#128533;', 'Not entirely clear &#129488;', 'Likely TRUE! &#128512;'],\n",
    "                        ['Likely FALSE! &#128533;', 'Perhaps not quite correct! &#129320;', 'Perhaps a little bit correct! &#128524;', 'Likely TRUE! &#128512;'],\n",
    "                        ['Likely FALSE! &#128533;', 'Perhaps not quite correct! &#129320;', 'Not entirely clear &#129488;', 'Perhaps a little bit correct! &#128524;', 'Likely TRUE! &#128512;'],\n",
    "                        ['Quite WRONG! &#128549;', 'Likely FALSE! &#128533;', 'Perhaps not quite correct! &#129320;', 'Perhaps a little bit correct! &#128524;', 'Likely TRUE! &#128512;', 'Quite TRUE! &#128513;'],\n",
    "                        ['Quite WRONG! &#128549;', 'Likely FALSE! &#128533;', 'Perhaps not quite correct! &#129320;', 'Not entirely clear &#129488;', 'Perhaps a little bit correct! &#128524;', 'Likely TRUE! &#128512;', 'Quite TRUE! &#128513;'],\n",
    "                        ['Liar, Liar! &#129396;', 'Quite WRONG! &#128549;', 'Likely FALSE! &#128533;', 'Perhaps not quite correct! &#129320;', 'Perhaps a little bit correct! &#128524;', 'Likely TRUE! &#128512;', 'Quite TRUE! &#128513;', 'Super TRUE! &#129299;'],\n",
    "                        ['Liar, Liar! &#129396;', 'Quite WRONG! &#128549;', 'Likely FALSE! &#128533;', 'Perhaps not quite correct! &#129320;', 'Not entirely clear &#129488;', 'Perhaps a little bit correct! &#128524;', 'Likely TRUE! &#128512;', 'Quite TRUE! &#128513;', 'Super TRUE! &#129299;'],\n",
    "                        ['PANTS ON FIRE &#128086;&#128293;', 'Liar, Liar! &#129396;', 'Quite WRONG! &#128549;', 'Likely FALSE! &#128533;', 'Perhaps not quite correct! &#129320;', 'Perhaps a little bit correct! &#128524;', 'Likely TRUE! &#128512;', 'Quite TRUE! &#128513;', 'Super TRUE! &#129299;', 'Spreading the GOSPEL OF TRUTH! &#129321;']]\n",
    "if reverse_resp_classes == 1:\n",
    "    for i, val in enumerate(response_classes):\n",
    "        if i >= 2:\n",
    "            response_classes[i] = list(reversed(val))\n",
    "if emojis_only == 1:\n",
    "    for i, val in enumerate(response_classes):\n",
    "        if i >= 2:\n",
    "            for j in range(len(val)):\n",
    "                response_classes[i][j] = re.search(r'&\\#\\d{6};', response_classes[i][j]).group(0)\n",
    "        if reverse_resp_classes == 0:\n",
    "            response_classes[10][0] = '&#128086;&#128293;'\n",
    "        else:\n",
    "            response_classes[10][9] = '&#128086;&#128293;'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Flask Instance\n",
    "Executing the following code cell will start the Flask instance. If everything works as intended the instance will listen for requests on your machine's local port (5000). After executing leave the code cell open/running and start browsing Twitter (X). Once you are done browsing, terminate the execution of the cell manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_texts = []\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/process', methods=['POST'])\n",
    "def process_text():\n",
    "    data = request.get_json()\n",
    "    tweet_text = data['text']\n",
    "\n",
    "    processed_text = get_tweet_text(tweet_text)\n",
    "\n",
    "    if len(processed_text) > 10:\n",
    "        if processed_text == 'THIS_TWEET_IS_AN_AD':\n",
    "            return_text = response_classes[0][0]\n",
    "        else:\n",
    "            classification = get_veracity(processed_text)\n",
    "            if len(classification.tolist()[0]) > 1:\n",
    "                return_text = response_classes[len(classification.tolist()[0])][int(torch.argmax(classification))]\n",
    "            else:\n",
    "                print(classification.item())\n",
    "                print('Outcome: ' + str(classification.item()))\n",
    "                return_text = response_classes[10][max(0, min(round((classification.item())*10),9))]\n",
    "    else:\n",
    "        return_text = 'Not enough text! &#128683;'\n",
    "\n",
    "    #time.sleep(2)\n",
    "    tweet_texts.append(tweet_text)\n",
    "    tweet_texts.append(processed_text)\n",
    "    #print(tweet_text)\n",
    "    return jsonify(return_text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing your Twitter (X) session, the following cell gives you the opportunity to view all the tweets that you have come across during your browsing session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TWEET:\n",
      "Saruei @Saruei_·12hTrust is the most dangerous weapon  #MGS35332K28K413K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Trust is the most dangerous weapon  #MGS\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "The_Real_Fly@The_Real_Fly·2h23 years later they blame Saudi Arabia for 9/11From CBS Evening News38371358.1K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "23 years later they blame Saudi Arabia for \n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "Catizen@CatizenAI·22h#CatizenVibe - Heal the World  \n",
      "Calling all Catizens!\n",
      "Vote, Share, Participate to rescue stray cats! \n",
      "\n",
      "Post your heartwarming story with stray Kitty and get $Ton rewards! \n",
      "\n",
      "Share Your Story with Stray Cats on Twitter and Telegram\n",
      "\n",
      "Format: \n",
      "-Video or Picture with TextShow more4K58K30K399K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "#CatizenVibe - Heal the World  \n",
      "Calling all Catizens!\n",
      "Vote, Share, Participate to rescue stray cats! \n",
      "\n",
      "Post your heartwarming story with stray Kitty and get $Ton rewards! \n",
      "\n",
      "Share Your Story with Stray Cats on Twitter and Telegram\n",
      "\n",
      "Format: \n",
      "-Video or Picture with TextShow more\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "Kpop Charts@kchartsmaster·1hLee Young Ji has released ‘Small Girl (feat. DOH KYUNGSOO)’ on all streaming platforms.From ㅈㅈ361.4K2.8K65K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Lee Young Ji has released ‘Small Girl (feat. DOH KYUNGSOO)’ on all streaming platforms.From ㅈㅈ\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "sonofabench@therealmrbench·11hTrudeau is pushing his National School Food Program for all children. His math does not add up. \n",
      "He wants it to be a fully universal program.  Does not matter where you are on the social economic scale.\n",
      "\n",
      "Quich numbers, then.\n",
      "$1 billion over 5 years.\n",
      "$200 million per year.\n",
      "ApproxShow more36217549162K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Trudeau is pushing his National School Food Program for all children. His math does not add up. \n",
      "He wants it to be a fully universal program.  Does not matter where you are on the social economic scale.\n",
      "\n",
      "Quich numbers, then.\n",
      "$1 billion over 5 years.\n",
      "$200 million per year.\n",
      "ApproxShow more\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "Republicans against Trump@RpsAgainstTrump·16hDr Fauci talks about his relationship with Trump: “He was really very upset about the fact that I had to get up and say…no, it's not going to disappear like magic, and, no, hydroxychloroquine doesn't work no matter what Laura Ingraham is telling you.”From The Recount1551.2K5.9K303K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Dr Fauci talks about his relationship with Trump: “He was really very upset about the fact that I had to get up and say…no, it's not going to disappear like magic, and, no, hydroxychloroquine doesn't work no matter what Laura Ingraham is telling you.”From The Recount\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "Manickam Tagore .Bமாணிக்கம் தாகூர்.ப@manickamtagore·5hMr K Suresh is a 8 term Dalit MP and the BJP opted for a 7 term upper class MP against a Dalit even for a pro tem speaker post . What it shows?2606322.1K88K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Mr K Suresh is a 8 term Dalit MP and the BJP opted for a 7 term upper class MP against a Dalit even for a pro tem speaker post . What it shows?\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "MSNBC@MSNBC·13hFIRST ON MSNBC: New audio from Trump interviews admitting he lost in 20201K3.1K7.5K471K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "FIRST ON MSNBC: New audio from Trump inter admitting he lost in \n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "RAM@pspkdhfs·22hKONIDELA Thaman   \n",
      "#BheemlanayakOST  28 th JUNE 4:05 pm \n",
      "\n",
      "30 FIREY TRACKS \n",
      "All the Way To Ur Ears For Years \n",
      "\n",
      "#Bheemla #Bheemlanayak22189808.2K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "KONIDELA Thaman   \n",
      "#BheemlanayakOST  28 th JUNE 4:05 pm \n",
      "\n",
      "30 FIREY TRACKS \n",
      "All the Way To Ur Ears For Years \n",
      "\n",
      "#Bheemla #Bheemlanayak\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "Lorde Updates@LordeUpdatesBR·Jun 20Last night, during one of her DJ sets, Charli XCX played “Green Light” by Lorde.From tina ⎕155915.8K154K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Last night, during one of her DJ sets, Charli XCX played “Green Light” by Lorde.From tina ⎕\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "Lorde Updates@LordeUpdatesBR·Jun 20Last night, during one of her DJ sets, Charli XCX played “Green Light” by Lorde.From tina ⎕155915.8K154K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Last night, during one of her DJ sets, Charli XCX played “Green Light” by Lorde.From tina ⎕\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "The Labour Party@UKLabour·4hLabour’s first step will deliver economic security. \n",
      "\n",
      "We will lead the world in the industries of the future.16320647434K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Labour’s first step will deliver economic security. \n",
      "\n",
      "We will lead the world in the industries of the future.\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "Manickam Tagore .Bமாணிக்கம் தாகூர்.ப@manickamtagore·5hMr K Suresh is a 8 term Dalit MP and the BJP opted for a 7 term upper class MP against a Dalit even for a pro tem speaker post . What it shows?2606322.1K88K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Mr K Suresh is a 8 term Dalit MP and the BJP opted for a 7 term upper class MP against a Dalit even for a pro tem speaker post . What it shows?\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "MSNBC@MSNBC·13hFIRST ON MSNBC: New audio from Trump interviews admitting he lost in 20201K3.1K7.5K471K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "FIRST ON MSNBC: New audio from Trump inter admitting he lost in \n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "RAM@pspkdhfs·22hKONIDELA Thaman   \n",
      "#BheemlanayakOST  28 th JUNE 4:05 pm \n",
      "\n",
      "30 FIREY TRACKS \n",
      "All the Way To Ur Ears For Years \n",
      "\n",
      "#Bheemla #Bheemlanayak22189808.2K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "KONIDELA Thaman   \n",
      "#BheemlanayakOST  28 th JUNE 4:05 pm \n",
      "\n",
      "30 FIREY TRACKS \n",
      "All the Way To Ur Ears For Years \n",
      "\n",
      "#Bheemla #Bheemlanayak\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "Lorde Updates@LordeUpdatesBR·Jun 20Last night, during one of her DJ sets, Charli XCX played “Green Light” by Lorde.From tina ⎕155915.8K154K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Last night, during one of her DJ sets, Charli XCX played “Green Light” by Lorde.From tina ⎕\n",
      "--------------------\n",
      "\n",
      "\n",
      "RAW TWEET:\n",
      "The Labour Party@UKLabour·4hLabour’s first step will deliver economic security. \n",
      "\n",
      "We will lead the world in the industries of the future.16320647634K\n",
      "--------------------\n",
      "\n",
      "\n",
      "CLEANED TWEET:\n",
      "Labour’s first step will deliver economic security. \n",
      "\n",
      "We will lead the world in the industries of the future.\n",
      "--------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for txt in tweet_texts:\n",
    "    if iter == 0:\n",
    "        print('RAW TWEET:')\n",
    "        iter = 1\n",
    "    else:\n",
    "        print('CLEANED TWEET:')\n",
    "        iter = 0\n",
    "    print(txt)\n",
    "    print('--------------------')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstration of Tweet Text Sanitization\n",
    "The following code cell illustrates the different stages of removing miscellaneous string content that comes with scraped tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historic Vids@historyinmemes·10hRussian hockey is different man1446315.9K1.4M\n",
      "--------------------\n",
      "10hRussian hockey is different man1446315.9K1.4M\n",
      "--------------------\n",
      "Russian hockey is different man1446315.9K1.4M\n",
      "--------------------\n",
      "Russian hockey is different man1446315.9K1.4M\n",
      "--------------------\n",
      "Russian hockey is different man1446315.9K1.4M\n",
      "--------------------\n",
      "Russian hockey is different man1446315.9K1.4M\n",
      "--------------------\n",
      "Russian hockey is different man\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "select_tweet = 'Historic Vids@historyinmemes·10hRussian hockey is different man1446315.9K1.4M'\n",
    "#select_tweet = tweet_texts[0]\n",
    "#select_tweet = 'Donald J. Trump@realDonaldTrump·Jan 6, 2021RSBN TV·23.2M views3:32:03 / 4:55:211:23:1723.2M views3:32:02From pscp.tv34K52K234K'\n",
    "#select_tweet = 'Donald J. Trump@realDonaldTrump·Jan 5, 2021From Team Trump (Text TRUMP to 88022)14K17K87K'\n",
    "print(select_tweet)\n",
    "print('--------------------')\n",
    "\n",
    "if re.match(r'^[^@]+@[^@]+·', select_tweet):\n",
    "    text = re.sub(r'^[^@]+@[^@]+·', '', select_tweet)\n",
    "    print(text)\n",
    "    print('--------------------')\n",
    "\n",
    "    text = re.sub(r'^(?:[A-Za-z]{3}\\s\\d+|\\d+[hm])', '', text)\n",
    "    print(text)\n",
    "    print('--------------------')\n",
    "\n",
    "    text = re.sub(r', \\d{4}', '', text)\n",
    "    print(text)\n",
    "    print('--------------------')\n",
    "\n",
    "    if text.startswith('From'):\n",
    "        print('RETURNING SHORT!')\n",
    "        print('--------------------')\n",
    "        sys.exit()\n",
    "\n",
    "    text = re.sub(r'\\dFrom.*', '', text)\n",
    "    print(text)\n",
    "    print('--------------------')\n",
    "\n",
    "    text = text.replace('views', '')\n",
    "    print(text)\n",
    "    print('--------------------')\n",
    "\n",
    "    last_word = text.split()\n",
    "    last_word = last_word[-1]\n",
    "    if bool(re.search(r'\\d', last_word)):\n",
    "        text = text.replace(last_word, '')\n",
    "        last_word = last_word[:re.search(r'\\d', last_word).start()]\n",
    "        text = text + last_word\n",
    "        print(text)\n",
    "        print('--------------------')\n",
    "\n",
    "    if not bool(re.search(r'[a-zA-Z]{5,}', text)):\n",
    "        text = ''\n",
    "        print(text)\n",
    "        print('--------------------')\n",
    "\n",
    "else:\n",
    "    print('Tweet is an AD!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
